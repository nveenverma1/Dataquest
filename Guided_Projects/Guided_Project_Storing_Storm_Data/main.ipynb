{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Storing Storm Data*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Recently, the International Hurricane Watchgroup (IHW) has been asked to update their analysis tools. Because of the increase in public awareness of hurricanes, they are required to be more diligient with the analysis of historical hurricane data they share across the organization. They have asked you, someone with experience in databases, to help work with their team to productionize their services.\n",
    "\n",
    "Accepting the job, their team tells you that they have been having trouble sharing data across the teams and keeping it consistent. From what they've told you, it seems that their method of sharing the data with their data anaylsts has been to save a CSV file on their local servers and have every data analyst pull the data down. Then, each analyst uses a local SQLite engine to store the CSV, run their queries, and send their results around.\n",
    "\n",
    "From what they have told you, you might be thinking that this is an inefficient way of sharing data. To understand what you will be working on, they have sent you a CSV file. Their CSV file contains the following fields:\n",
    "\n",
    ">fid - ID for the row<br>\n",
    "year - Recorded year<br>\n",
    "month - Recorded month<br>\n",
    "day - Recorded date<br>\n",
    "ad_time - Recorded time in UTC<br>\n",
    "btid - Hurricane ID<br>\n",
    "name - Name of the hurricane<br>\n",
    "lat - Latitude of the recorded location<br>\n",
    "long - Longitude of the recorded location<br>\n",
    "wind_kts - Wind speed in knots per second<br>\n",
    "pressure - Atmospheric pressure of the hurricane<br>\n",
    "cat - Hurricane category<br>\n",
    "basin - The basin the hurricane is located<br>\n",
    "shape_leng - Hurricane shape length<br>\n",
    "\n",
    "\n",
    "In this Guided Project, you will be using the local installed version of Postgres you installed from the previous project. This is much different than previous Guided Projects as you will be using your own notebook and your own Python environment instead of Dataquest's. Your job is to show that you can create a database that will accomplish the following requirements:\n",
    "\n",
    "- Database for the IHW to store their tables.\n",
    "- Table that contains the fields detailed in the CSV file\n",
    "- User that can update, read, and insert into a table of the data.\n",
    "- Insert the data into the table.\n",
    "\n",
    "In the next screen, the IHW has given you a sample file to work with. So, let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading CSV File\n",
    "\n",
    "There are two ways you can work with the CSV file in this project. The first, is that you can download the file from this link. Otherwise, you can use Python to programmatically download the file and read it like any other file. This is possible using the Python standard library, `urllib`.\n",
    "\n",
    "```\n",
    "import io\n",
    "from urllib import request\n",
    "\n",
    "response = request.urlopen('https://www.example.com/some_file.csv')\n",
    "reader = csv.reader(io.TextIOWrapper(response))\n",
    "\n",
    "for line in reader:\n",
    "    print(line)\n",
    "```    \n",
    "    \n",
    "The `urlopen()` method is part of the `request` module in the `urllib` library. It opens up the webpage requested and creates an HTML response object. Before we can use the response object as a file, we need to use another module, `io`.\n",
    "\n",
    "We use the `io` module to fake a file descriptor by using the `TextIOWrapper()` method. This wraps any string-like object and forces it to act like a Python file descriptor. You can choose to open the file locally or use the `urlopen()` in your own project but we will assume you are using the `urlopen()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FID</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>AD_TIME</th>\n",
       "      <th>BTID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LONG</th>\n",
       "      <th>WIND_KTS</th>\n",
       "      <th>PRESSURE</th>\n",
       "      <th>CAT</th>\n",
       "      <th>BASIN</th>\n",
       "      <th>Shape_Leng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>1957</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1800Z</td>\n",
       "      <td>63</td>\n",
       "      <td>NOTNAMED</td>\n",
       "      <td>22.5</td>\n",
       "      <td>-140.0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>TS</td>\n",
       "      <td>Eastern Pacific</td>\n",
       "      <td>1.140175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002</td>\n",
       "      <td>1961</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1200Z</td>\n",
       "      <td>116</td>\n",
       "      <td>PAULINE</td>\n",
       "      <td>22.1</td>\n",
       "      <td>-140.2</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>TS</td>\n",
       "      <td>Eastern Pacific</td>\n",
       "      <td>1.166190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>1962</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>0600Z</td>\n",
       "      <td>124</td>\n",
       "      <td>C</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-140.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>TS</td>\n",
       "      <td>Eastern Pacific</td>\n",
       "      <td>2.102380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004</td>\n",
       "      <td>1967</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0600Z</td>\n",
       "      <td>168</td>\n",
       "      <td>DENISE</td>\n",
       "      <td>16.6</td>\n",
       "      <td>-139.5</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>TS</td>\n",
       "      <td>Eastern Pacific</td>\n",
       "      <td>2.121320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005</td>\n",
       "      <td>1972</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>1200Z</td>\n",
       "      <td>251</td>\n",
       "      <td>DIANA</td>\n",
       "      <td>18.5</td>\n",
       "      <td>-139.8</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>H1</td>\n",
       "      <td>Eastern Pacific</td>\n",
       "      <td>1.702939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    FID  YEAR  MONTH  DAY AD_TIME  BTID      NAME   LAT   LONG  WIND_KTS  \\\n",
       "0  2001  1957      8    8   1800Z    63  NOTNAMED  22.5 -140.0        50   \n",
       "1  2002  1961     10    3   1200Z   116   PAULINE  22.1 -140.2        45   \n",
       "2  2003  1962      8   29   0600Z   124         C  18.0 -140.0        45   \n",
       "3  2004  1967      7   14   0600Z   168    DENISE  16.6 -139.5        45   \n",
       "4  2005  1972      8   16   1200Z   251     DIANA  18.5 -139.8        70   \n",
       "\n",
       "   PRESSURE CAT            BASIN  Shape_Leng  \n",
       "0         0  TS  Eastern Pacific    1.140175  \n",
       "1         0  TS  Eastern Pacific    1.166190  \n",
       "2         0  TS  Eastern Pacific    2.102380  \n",
       "3         0  TS  Eastern Pacific    2.121320  \n",
       "4         0  H1  Eastern Pacific    1.702939  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io \n",
    "import csv\n",
    "from urllib import request\n",
    "import pandas as pd\n",
    "\n",
    "response = request.urlopen(\"https://dq-content.s3.amazonaws.com/251/storm_data.csv\")\n",
    "reader = csv.reader(io.TextIOWrapper(response))\n",
    "\n",
    "df = pd.read_csv(io.TextIOWrapper(response))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Various Columns and deciding their required Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FID', 'YEAR', 'MONTH', 'DAY', 'AD_TIME', 'BTID', 'LAT', 'LONG', 'WIND_KTS', 'PRESSURE', 'Shape_Leng']\n",
      "59228 5\n",
      "2008 4\n",
      "12 2\n",
      "31 2\n",
      "1800Z 5\n",
      "1410 4\n",
      "69.0 4\n",
      "180.0 5\n",
      "165 3\n",
      "1024 4\n",
      "11.18034 8\n"
     ]
    }
   ],
   "source": [
    "columns = list(df.columns)\n",
    "num_columns = columns[:6] + columns[7:-3] + columns[-1:]\n",
    "print(num_columns)\n",
    "\n",
    "for item in num_columns:\n",
    "    print(max(df[item].value_counts().index), len(str(max(df[item].value_counts().index))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NUMERICAL COLUMNS DATATYPES:\n",
    "\n",
    "- For `FID`:\n",
    "    - We wil use INTEGER datatype. Since, it's largest value is 59228.<br><br>\n",
    "- Columns `YEAR`, `MONTH`, `DAY` represent any particular date and `AD_TIME` represents a record of the time in [UTC (Coordinated Universal Time)](https://en.wikipedia.org/wiki/Coordinated_Universal_Time):\n",
    "    - Here, we will combine all of them into a single column and use TIMESTAMP datatype for this column.<br><br>\n",
    "- For `BTID`, `WIND_KTS` and `PRESSURE`:\n",
    "    - We will use SMALLINT. Since, there maximum values are 1410, 165 and 1024 respectively.<br><br>\n",
    "- For `LAT` and `LONG`:\n",
    "    - We will use DECIMAL datatype with precision 4 and scale 1. Since, they have max. 3 digits before decimal and 1 digit after decimal.<br><br>\n",
    "- For `Shape_Leng`:\n",
    "    - We will use DECIMAL datatype with precision 8 and scale 6. Since, it has max. two digits before decimal and 6 digits after decimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NAME', 'CAT', 'BASIN']\n",
      "(9, 'SEBASTIEN')\n",
      "(2, 'TS')\n",
      "(15, 'Eastern Pacific')\n"
     ]
    }
   ],
   "source": [
    "str_columns = [columns[x] for x in (6, 11, 12)]\n",
    "print(str_columns)\n",
    "\n",
    "for item in str_columns:\n",
    "    print(max([(len(x), x) for x in df[item].unique()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STRING COLUMNS DATATYPES\n",
    "- For `NAME`:\n",
    "    - We will use VARCHAR(10) since max length is 9\n",
    "- For `CAT`:\n",
    "    - We will use VARCHAR(2) since max length is 2\n",
    "- For `BASIN`:\n",
    "    - we will use VARCHAR(16) since max length is 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Database First\n",
    "\n",
    "import psycopg2\n",
    "from datetime import datetime\n",
    "\n",
    "conn = psycopg2.connect(\"dbname=postgres user=postgres password=postgres host=localhost\")\n",
    "conn.autocommit = True\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"DROP DATABASE IF EXISTS ihw\")\n",
    "cur.execute(\"CREATE DATABASE ihw\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\"dbname=ihw user=postgres password=postgres host=localhost\")\n",
    "conn.autocommit = True\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"DROP TABLE IF EXISTS hurricanes\")\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE hurricanes (\n",
    "        fid INTEGER PRIMARY KEY,\n",
    "        date TIMESTAMP,\n",
    "        btid SMALLINT,\n",
    "        name VARCHAR(10),\n",
    "        lat DECIMAL(4, 1), \n",
    "        long DECIMAL(4, 1), \n",
    "        wind_kts SMALLINT, \n",
    "        pressure SMALLINT,\n",
    "        category VARCHAR(2),\n",
    "        basin VARCHAR(16),\n",
    "        shape_length  DECIMAL(8, 6)\n",
    "        )\n",
    "    \"\"\")\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Users\n",
    "\n",
    "With a table set up, it's now time to create a user on the Postgres database that can insert, update, and read the data but not delete. This is to make sure that someone who might get a hold of this user does not issue a destructive command. Essentially, this is like creating a \"data production\" user whose job it is is to always write new and existing data to the table.\n",
    "\n",
    "Futhermore, even though it wasn't according to the spec, we know that the IHW team's analysts just run read queries on the data. Also, since the analysts only know SQLite queries, they may not be well-versed in a production database. As such, it might be risky handing out a general production user for them to query their data.\n",
    "\n",
    "From what you have learned about security and restricting well meaning users, it might be a good idea to restrict those analysts from some commands. Those commands can be anything from adding new data to the table or changing the values. You should decide what commands should be given to the analyst user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\"dbname=ihw user=postgres password=postgres host=localhost\")\n",
    "conn.autocommit = True\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"CREATE USER ihw_production WITH PASSWORD 'ihw.production.whi'\")\n",
    "cur.execute(\"CREATE USER ihw_analyst WITH PASSWORD 'ihw.analyst.whi'\")\n",
    "\n",
    "cur.execute(\"REVOKE ALL ON hurricanes FROM ihw_production\")\n",
    "cur.execute(\"REVOKE ALL ON hurricanes FROM ihw_analyst\")\n",
    "cur.execute(\"GRANT INSERT, UPDATE, SELECT ON hurricanes TO ihw_production\")\n",
    "cur.execute(\"GRANT SELECT ON hurricanes TO ihw_analyst\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Readonly Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\"dbname=ihw user=postgres password=postgres host=localhost\")\n",
    "conn.autocommit = True\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"DROP GROUP IF EXISTS analysts\")\n",
    "\n",
    "cur.execute(\"CREATE GROUP analysts NOLOGIN\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\"dbname=ihw user=ihw_production password=ihw.production.whi host=localhost\")\n",
    "conn.autocommit = True\n",
    "cur = conn.cursor()\n",
    "\n",
    "response = request.urlopen(\"https://dq-content.s3.amazonaws.com/251/storm_data.csv\")\n",
    "reader = csv.reader(io.TextIOWrapper(response))\n",
    "next(reader)\n",
    "\n",
    "mogrified_values = []\n",
    "\n",
    "for row in reader:\n",
    "    date = datetime(int(row[1]), int(row[2]), int(row[3]), hour=int(row[4][:2]), minute=int(row[4][2:-1]))\n",
    "    updated_row = [row[0], date] + row[5:]\n",
    "#     print(updated_row)\n",
    "\n",
    "    mogrified = cur.mogrify(\"(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\", updated_row).decode('utf-8')\n",
    "    mogrified_values.append(mogrified)\n",
    "    \n",
    "cur.execute(\"INSERT INTO hurricanes VALUES \" + \",\".join(mogrified_values))\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirming Data is read into PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2001, datetime.datetime(1957, 8, 8, 18, 0), 63, 'NOTNAMED', Decimal('22.5'), Decimal('-140.0'), 50, 0, 'TS', 'Eastern Pacific', Decimal('1.140175')), (2002, datetime.datetime(1961, 10, 3, 12, 0), 116, 'PAULINE', Decimal('22.1'), Decimal('-140.2'), 45, 0, 'TS', 'Eastern Pacific', Decimal('1.166190')), (2003, datetime.datetime(1962, 8, 29, 6, 0), 124, 'C', Decimal('18.0'), Decimal('-140.0'), 45, 0, 'TS', 'Eastern Pacific', Decimal('2.102380'))]\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect(\"dbname=ihw user=ihw_analyst password=ihw.analyst.whi host=localhost\")\n",
    "# conn.autocommit = True\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"SELECT * FROM hurricanes limit 3\")\n",
    "print(cur.fetchall())\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\"dbname=ihw user=postgres password=postgres host=localhost\")\n",
    "conn.autocommit = True\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"REVOKE CONNECT ON DATABASE ihw FROM public;\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\"dbname=ihw user=postgres password=postgres host=localhost\")\n",
    "conn.autocommit = True\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"\"\"SELECT pid, pg_terminate_backend(pid) \n",
    "FROM pg_stat_activity \n",
    "WHERE datname = 'ihw' AND pid <> pg_backend_pid();\"\"\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
